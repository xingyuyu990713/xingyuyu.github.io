








# 多网卡Bonding

Bonding（绑定）是一种将多个网络接口（通常是以太网接口）聚合为一个逻辑接口的技术。这种聚合可以实现负载均衡、冗余和故障转移等功能。bonding 模式定义了网络接口如何在 bond 中工作。

## 1.常见的bonding模式

1. **balance-rr（模式0，Round-robin 轮询模式）**：在这种模式下，数据包按顺序分发到各个从接口，从而实现负载均衡。这种模式可以提高总体传输速率，但可能导致接收端的数据包乱序。这种模式需要交换机支持。

2. **active-backup（模式1，主备模式）**：在这种模式下，仅有一个从接口处于活动状态，其他接口处于备份状态。如果活动接口出现故障，系统会自动切换到备份接口。这种模式主要用于实现故障转移，不需要交换机支持。

3. **balance-xor（模式2，异或负载均衡模式）**：此模式根据源 MAC 地址与目标 MAC 地址的异或结果将流量分配到从接口。这可以实现负载均衡，但同一流量始终使用相同的从接口。这种模式需要交换机支持。

4. **broadcast（模式3，广播模式）**：在这种模式下，所有数据包都通过所有从接口发送。这种模式主要用于实现冗余和故障转移，不需要交换机支持。

5. **802.3ad（模式4，IEEE 802.3ad 动态链接聚合模式）**：这种模式要求交换机支持 IEEE 802.3ad LACP（Link Aggregation Control Protocol，链路聚合控制协议）。在此模式下，根据 LACP 协议的负载均衡策略将流量分配到从接口。这种模式可以提高传输速率并实现故障转移。

6. **balance-tlb（模式5，适应性传输负载均衡模式）**：此模式仅在发送流量时进行负载均衡。根据从接口的当前负载将流量分配到从接口。接收流量仅通过一个从接口。这种模式不需要交换机支持。

7. **balance-alb（模式6，适应性负载均衡模式）**：这种模式在发送和接收流量时都进行负载均衡。发送负载均衡类似于 balance-tlb 模式，而接收负载均衡则需要修改从接口的 MAC 地址。这种模式不需要交换机支持。

   每种 bonding 模式都有其特定的使用场景和优劣。在选择合适的模式时，需要考虑网络需求、交换机支持的功能以及对性能、冗余和故障转移的需求。

   例如，如果网络环境要求高可用性和故障转移，但不需要负载均衡，那么可以选择 active-backup（模式1）。如果您的网络环境支持 LACP，并要求较高的传输速率和故障转移功能，那么可以选择 802.3ad（模式4）。

## 2.配置bonding模式

> 案例：我们有eth0、eth1两个网卡，模式使用active-backup

### 2.1使用nmcli命令配置

在 Linux 系统中，配置 bonding 模式的方法有很多，这里我将以使用 NetworkManager 的命令行工具 `nmcli` 为例来演示如何配置 bonding 模式。

以下是使用 `nmcli` 配置 bonding 的步骤：

1.首先，创建一个新的 bond 连接。您需要指定 bond 的名称（例如 `mybond0`）和网络接口名称（例如 `bond0`）。同时，您需要为 bond 连接设置一个模式（例如 `mode=active-backup`）。执行以下命令：

```css
nmcli con add type bond con-name mybond0 ifname bond0 mode active-backup(需要执行第三步)
或者
nmcli con add type bond con-name mybond0 ifname bond0 mode active-backup ipv4.method manual ipv4.addresses 10.0.0.100/24(不需要执行第三步)
```

2.将物理接口添加到 bond 连接。请根据您的实际网络接口名称替换 eth0 和 eth1。执行以下命令：

```css
nmcli con add type ethernet con-name mybond0-eth0 ifname eth0 master bond0	#bond0要跟上面ifname 后面的名字对应
nmcli con add type ethernet con-name mybond0-eth1 ifname eth1 master bond0
或者
nmcli con add type bond-slave con-name mybond0-eth0 ifname eth0 master bond0	#如果con-name 不指定名字，默认是bond-slave-eth0
nmcli con add type bond-slave con-name mybond0-eth1 ifname eth1 master bond0

[root@centos8 network-scripts]#nmcli connection add type bond-slave ifname eth0 master bond0
Connection 'bond-slave-eth0' (c84905bd-86c7-44d3-9840-073f5c3fee49) successfully added.
[root@centos8 network-scripts]#nmcli connection add type bond-slave ifname eth1 master bond0
Connection 'bond-slave-eth1' (43392c2b-99c6-4341-9119-93f8bbbe2e05) successfully added.
[root@centos8 network-scripts]#nmcli connection
NAME             UUID                                  TYPE      DEVICE
eth0             5fb06bd0-0bb0-7ffb-45f1-d6edd65f3e03  ethernet  eth0
eth1             9c92fad9-6ecb-3e6c-eb4d-8a47c6f50c04  ethernet  eth1
mybond0          0c52d042-a5ee-49e6-a16a-fed07cccc980  bond      bond0
bond-slave-eth0  c84905bd-86c7-44d3-9840-073f5c3fee49  ethernet  --
bond-slave-eth1  43392c2b-99c6-4341-9119-93f8bbbe2e05  ethernet  --
[root@centos8 network-scripts]#
    
#查看bond0的网络绑定(bonding)接口的详细信息和状态
[root@centos8 network-scripts]#cat /proc/net/bonding/bond0
Ethernet Channel Bonding Driver: v3.7.1 (April 27, 2011)

Bonding Mode: fault-tolerance (active-backup) #绑定模式
Primary Slave: None
Currently Active Slave: eth1	#可以看出那一个是主的
MII Status: up
MII Polling Interval (ms): 100
Up Delay (ms): 0
Down Delay (ms): 0
Peer Notification Delay (ms): 0

Slave Interface: eth0
MII Status: up
Speed: 10000 Mbps
Duplex: full
Link Failure Count: 0
Permanent HW addr: 00:0c:29:cd:ed:b8
Slave queue ID: 0

Slave Interface: eth1
MII Status: up
Speed: 10000 Mbps
Duplex: full
Link Failure Count: 0
Permanent HW addr: 00:0c:29:cd:ed:c2
Slave queue ID: 0
[root@centos8 network-scripts]#

```

可以将 `type ethernet` 替换为 `type bond-slave`。实际上，在某些发行版中，它们是等效的。当您将一个网络接口添加到 bond 连接时，指定 `type bond-slave` 可以使语义更清晰，因为它明确表示您将该接口作为从接口添加到 bond 连接。

3.配置 bond 接口的 IP 地址、子网掩码、默认网关和 DNS（可选）。例如，要配置静态 IP 地址，请执行以下命令：

```css
nmcli con modify mybond0 ipv4.method manual ipv4.addresses 10.0.0.100/24 ipv4.gateway 10.0.0.1 ipv4.dns "8.8.8.8, 8.8.4.4"
```

4.启用 bond 连接：

```css
nmcli con up mybond0
```

5.验证 bond 连接配置。要查看 bond 连接的详细信息，请执行以下命令：

```css
nmcli con show mybond0
```

6.还可以使用 `cat` 命令查看 `/proc/net/bonding/bond0` 文件，以获取有关 bond 接口状态的详细信息：

```css
cat /proc/net/bonding/bond0  #可以看到两个网卡中哪个是备份，哪个是主
```

7.删除网卡

```css
nmcli connection delete mybond0
nmcli connection delete  bond-slave-eth0
nmcli connection delete  bond-slave-eth1
```

### 2.2.使用配置文件的方式

在基于 RHEL 和 CentOS 的系统中，您可以使用 `ifcfg-*` 配置文件来配置 bonding。以下是使用配置文件配置 active-backup 模式的步骤：

1.首先，创建一个名为 `ifcfg-bond0` 的 bond 配置文件。在 `/etc/sysconfig/network-scripts/` 目录下创建一个新文件：

```css
sudo nano /etc/sysconfig/network-scripts/ifcfg-bond0
```

2.在 `ifcfg-bond0` 文件中添加以下内容：

```bash
DEVICE=bond0
NAME=bond0
TYPE=Bond
BONDING_MASTER=yes
IPADDR=10.0.0.100
PREFIX=24
GATEWAY=10.0.0.1
DNS1=8.8.8.8
DNS2=8.8.4.4
ONBOOT=yes
BOOTPROTO=none
BONDING_OPTS="mode=active-backup miimon=100 fail_over_mac=1" #也可以写成BONDING_OPTS="mode=1 miimon=100"

#mode=1：这表示 bonding 的模式是 active-backup（模式1），在这种模式下，只有一个从接口是活动的，其他接口则处于备用状态。当活动接口失效时，备用接口将接管流量。
#miimon=100：这是一个用于监控网络接口链路状态的参数。它表示每100毫秒（ms）检查一次链路状态。如果检测到链路故障，系统将自动切换到其他可用的接口。
#fail_over_mac=1：此参数用于配置 MAC 地址的故障转移策略。fail_over_mac=1 表示 bonding 设备将使用活动从接口的 MAC 地址。当从接口发生切换时，bonding 设备的 MAC 地址也会相应地更改。这个可以不写。综上所述，BONDING_OPTS="mode=1 miimon=100 fail_over_mac=1" 表示配置 bonding 设备为 active-backup 模式，每 100ms 检查一次接口链路状态，并在故障转移时更改 bonding 设备的 MAC 地址。
```

3.修改您的网络接口（eth0 和 eth1）的配置文件。打开 `/etc/sysconfig/network-scripts/ifcfg-eth0` 和 `/etc/sysconfig/network-scripts/ifcfg-eth1`，并修改它们的内容以指向 bond0：

对于 `ifcfg-eth0`：

```bash
DEVICE=eth0
TYPE=Ethernet
BOOTPROTO=none
ONBOOT=yes
MASTER=bond0
SLAVE=yes
```

对于 `ifcfg-eth1`：

```bash
DEVICE=eth1
TYPE=Ethernet
BOOTPROTO=none
ONBOOT=yes
MASTER=bond0
SLAVE=yes

#MASTER=bond0：这表示此网络接口（eth1）的主设备是 bond0。换句话说，eth1 将成为 bond0 的一个从接口（slave interface），与其他从接口一起共享 bond0 的负载。
#SLAVE=yes：此选项指示该网络接口（eth1）是一个从接口。将 SLAVE 设置为 yes 表示 eth1 是 bond0 的从接口，将根据 bonding 配置的模式和策略与其他从接口一起工作。
```

4.保存并关闭所有打开的配置文件。

5.重启网络服务以使更改生效：

```css
sudo systemctl restart network
```

6.或者，在 CentOS 8 或 RHEL 8 上：

```css
sudo nmcli connection reload
sudo nmcli connection down bond0
sudo nmcli connection up bond0
```

7.验证 bond 配置。要查看 bond 接口的详细信息，请执行以下命令：

```css
cat /proc/net/bonding/bond0
```

以上步骤应该可以帮助您使用配置文件在基于 RHEL 和 CentOS 的系统中配置 bonding 的 active-backup 模式。请注意，在其他发行版（如 Debian 和 Ubuntu）上，配置文件和步骤可能会有所不同。

## 3.CentOS7配置bonding模式

在CentOS 7中，`team` 是一种新的网络聚合技术，用于替代传统的`bonding`。`team`提供了类似于`bonding`的功能，但具有更好的可扩展性和性能。尽管`team`和`bonding`有许多相似之处，但它们的模式和配置略有不同。

在CentOS 7中，`team`支持以下几种模式：

1. **Broadcast**：在此模式下，所有的数据包都会通过所有的网络接口发送，确保所有数据包都能到达目标。这种模式主要用于实现数据包的可靠传输。
2. **Round-robin**：这种模式提供负载均衡和故障切换功能。数据包会依次在各个网络接口间轮询发送，从而实现负载均衡。
3. **Active-backup**：在这种模式下，只有一个网络接口处于激活状态，其他接口处于备份状态。当激活接口出现故障时，备份接口会自动接管数据传输。这种模式主要用于实现高可用性。
4. **Load balancing**：此模式下，`team`会根据网络流量动态地分配负载到不同的网络接口。这种模式用于实现负载均衡和高可用性。
5. **LACP（Link Aggregation Control Protocol，802.3ad）**：这种模式基于IEEE 802.3ad标准，需要交换机支持LACP。它提供了负载均衡和故障切换功能。



### 3.1使用nmcli命令配置

在 CentOS 7 中，`nmcli` 命令也可以用于配置 bonding。同时，CentOS 7 中确实引入了一个名为 `team` 的新特性，它可以作为 bonding 的替代方案。但是在这里，我们仍然将介绍如何使用 `nmcli` 配置 bonding，而不是 team。

下面是使用 `nmcli` 在 CentOS 7 中配置 bonding 的步骤：

1.创建一个名为 bond0 的新 bond 连接：

```css
sudo nmcli con add type bond con-name bond0 ifname bond0 mode active-backup
```

2.为 bond0 分配一个静态 IP 地址、子网掩码、默认网关和 DNS 服务器：

```css
sudo nmcli con mod bond0 ipv4.addresses "10.0.0.100/24" ipv4.gateway "10.0.0.1" ipv4.dns "8.8.8.8,8.8.4.4" ipv4.method manual
```

`con mod`：`con`表示"connection"（连接），`mod`表示"modify"（修改）。这个组合表示修改一个现有的网络连接。

`bond0`：这是要修改的网络连接的名称。在这个例子中，它是一个名为`bond0`的网络绑定（bonding）连接。

`ipv4.addresses "10.0.0.100/24"`：这个参数表示要将IPv4地址设置为`10.0.0.100`，子网掩码长度为`24`（即`255.255.255.0`）。

`ipv4.gateway "10.0.0.1"`：这个参数表示要将IPv4网关设置为`10.0.0.1`。

`ipv4.dns "8.8.8.8,8.8.4.4"`：这个参数表示要将IPv4 DNS服务器设置为`8.8.8.8`和`8.8.4.4`（这些是Google的公共DNS服务器）。

`ipv4.method manual`：这个参数表示要使用手动（静态）IP地址分配方法，而不是动态（如DHCP）分配方法。

请根据您的网络环境替换 IP 地址、子网掩码、默认网关和 DNS 服务器。

3.将您的网络接口（例如 eth0 和 eth1）添加为 bond0 的从接口：

```css
sudo nmcli con add type ethernet con-name bond0-eth0 ifname eth0 master bond0
sudo nmcli con add type ethernet con-name bond0-eth1 ifname eth1 master bond0
```

4.最后，启用 bond0 连接：

```css
sudo nmcli con up bond0
```

5.可以通过以下命令验证 bond 配置：

```css
nmcli con show bond0
```

这样，您就可以使用 `nmcli` 命令在 CentOS 7 中配置 bonding 了。如果您想使用 team 而非 bonding，配置过程将略有不同。

### 3.2使用配置文件的方式

在 CentOS 7 中配置 bonding 模式的方法与 CentOS 6 和 RHEL 系列非常相似。您可以使用 `ifcfg-*` 配置文件来配置 bonding。以下是如何在 CentOS 7 中配置 bonding 的步骤：

1.首先，加载 bonding 内核模块。您可以通过执行以下命令来实现：

```css
sudo modprobe bonding
```

2.创建一个名为 `ifcfg-bond0` 的 bond 配置文件。在 `/etc/sysconfig/network-scripts/` 目录下创建一个新文件：

```css
sudo nano /etc/sysconfig/network-scripts/ifcfg-bond0
```

3.在 `ifcfg-bond0` 文件中添加以下内容：

```css
DEVICE=bond0
NAME=bond0
TYPE=Bond
BONDING_MASTER=yes
IPADDR=10.0.0.100
PREFIX=24
GATEWAY=10.0.0.1
DNS1=8.8.8.8
DNS2=8.8.4.4
ONBOOT=yes
BOOTPROTO=none
BONDING_OPTS="mode=active-backup miimon=100"
```

请根据您的网络环境替换 IP 地址、子网掩码、默认网关和 DNS 服务器。在 BONDING_OPTS 中，`mode=active-backup` 表示我们在这里使用 active-backup（模式1）。`miimon=100` 表示每 100 毫秒检查一次接口的链路状态。

4.修改您的网络接口（eth0 和 eth1）的配置文件。打开 `/etc/sysconfig/network-scripts/ifcfg-eth0` 和 `/etc/sysconfig/network-scripts/ifcfg-eth1`，并修改它们的内容以指向 bond0：

对于 `ifcfg-eth0`：

```css
DEVICE=eth0
TYPE=Ethernet
BOOTPROTO=none
ONBOOT=yes
MASTER=bond0
SLAVE=yes
```

对于 `ifcfg-eth1`：

```css
DEVICE=eth1
TYPE=Ethernet
BOOTPROTO=none
ONBOOT=yes
MASTER=bond0
SLAVE=yes
```

5.保存并关闭所有打开的配置文件。

6.重启网络服务以使更改生效：

```css
sudo systemctl restart network
```

7.验证 bond 配置。要查看 bond 接口的详细信息，请执行以下命令：

```css
cat /proc/net/bonding/bond0
```

以上步骤应该可以帮助您在 CentOS 7 中配置 bonding 模式。在其他发行版（如 Debian、Ubuntu 或其他基于 RHEL 的发行版）上，配置文件和步骤可能会有所不同。

### 3.3.CentOS7配置team模式

在 CentOS 7 中，可以使用 `nmcli` 命令来配置 team。以下是使用 `nmcli` 配置 team 的步骤：

1.首先，安装 `teamd` 软件包（如果尚未安装）：

```css
sudo yum install -y teamd
```

2.使用 `nmcli` 创建一个名为 team0 的新 team 连接：

```css
sudo nmcli con add type team con-name team0 ifname team0
```

3.为 team0 分配静态 IP 地址、子网掩码、默认网关和 DNS 服务器：

```css
sudo nmcli con mod team0 ipv4.addresses "10.0.0.100/24" ipv4.gateway "10.0.0.1" ipv4.dns "8.8.8.8,8.8.4.4" ipv4.method manual
```

请根据您的网络环境替换 IP 地址、子网掩码、默认网关和 DNS 服务器。

4.定义 team 连接的配置文件。在本例中，我们将使用默认的 round-robin（循环）运行模式。创建一个名为 `team-config.json` 的文件，并添加以下内容：

```css
{
    "device": "team0",
    "runner": {
        "name": "roundrobin"
    }
}
```

5.将配置文件应用到 team0 连接：

```css
sudo nmcli con mod team0 team.config "$(cat team-config.json)"
#可以不使用配置文件，直接将
sudo nmcli con add type team con-name team0 ifname team0 config '{"runner": {"name": "loadbalance"}}'
```

这里的loadbalance，包括上面配置文件里面的都都是字符串，不可以加空格。

6.将您的网络接口（例如 eth0 和 eth1）添加为 team0 的端口：

```css
sudo nmcli con add type team-slave con-name team0-eth0 ifname eth0 master team0
sudo nmcli con add type team-slave con-name team0-eth1 ifname eth1 master team0
```

7.启用 team0 连接：

```css
sudo nmcli con up team0
```

8.验证 team 配置：

```css
nmcli con show team0
```

现在您已经使用 `nmcli` 命令在 CentOS 7 中配置了一个 team。这个示例使用了 round-robin（循环）运行模式，但 team 支持其他运行模式，如 broadcast、active-backup 等。要使用其他运行模式，只需在 `team-config.json` 文件中修改相应的设置。

下面是真实配置

```bash
#创建一个名为myteam0的网络接口，接口名称：team0，模式为负载均衡(loadbalance),json格式，键值对
[root@centos7 ~]#nmcli connection add type team con-name myteam0 ifname team0 config '{"runner":{"name":"loadbalance"}}' ipv4.addresses 10.0.0.102/24 ipv4.method manual ipv4.dns 10.0.0.2 ipv4.gateway 10.0.0.2
连接 "myteam0" (b13861c7-0fb5-47f5-ab34-8d3ad076c8db) 已成功添加。
[root@centos7 ~]#nmcli connection
NAME        UUID                                  TYPE      DEVICE
eth0        f29c6dae-a938-4814-b082-708b99c6a6ce  ethernet  eth0
有线连接 2  b94ed9fc-67c7-3d41-9758-20fa1923a77a  ethernet  eth1
myteam0     b13861c7-0fb5-47f5-ab34-8d3ad076c8db  team      team0
有线连接 1  be8896bc-1e35-325a-934f-839f54564f31  ethernet  --
[root@centos7 ~]#

#将现有的网络接口eth0、eth1添加为名位team0的Team接口的从接口(slave interface)
[root@centos7 network-scripts]#nmcli connection add type team-slave ifname eth0 master team0
Connection 'team-slave-eth0' (6c079b02-ac95-403f-b865-77d47b3ec14d) successfully added.
[root@centos7 network-scripts]#nmcli connection add type team-slave ifname eth1 master team0
Connection 'team-slave-eth1' (c869f6e8-0e81-433a-ad20-3caee07f54c2) successfully added.
[root@centos7 network-scripts]#nmcli connection
NAME                UUID                                  TYPE      DEVICE
eth0                f29c6dae-a938-4814-b082-708b99c6a6ce  ethernet  eth0
Wired connection 1  89ad609e-4b4c-3622-8f35-8b7485b4b4bf  ethernet  eth1
myteam0             b13861c7-0fb5-47f5-ab34-8d3ad076c8db  team      team0
team-slave-eth0     6c079b02-ac95-403f-b865-77d47b3ec14d  ethernet  --
team-slave-eth1     c869f6e8-0e81-433a-ad20-3caee07f54c2  ethernet  --
[root@centos7 network-scripts]#
#nmcli connection add：使用 nmcli 创建一个新的网络连接。
#type team-slave：设置新连接的类型为 Team 接口的从接口。
#ifname eth0：指定要添加为从接口的现有网络接口名称，这里是 eth0。
#master team0：指定要将从接口添加到的 Team 接口的名称，这里是 team0。
#通过运行此命令，您将把现有的网络接口（eth0）添加为名为 team0 的 Team 接口的从接口。这样，eth0 会成为 team0 的一部分，从而实现网络负载均衡、故障切换等功能，具体取决于所配置的 Team 接口模式。

#激活从接口，意味着这两个从接口 将启动并加入到相应的Team接口中。
[root@centos7 network-scripts]#nmcli connection
NAME                UUID                                  TYPE      DEVICE
myteam0             b13861c7-0fb5-47f5-ab34-8d3ad076c8db  team      team0
team-slave-eth0     6c079b02-ac95-403f-b865-77d47b3ec14d  ethernet  eth0
team-slave-eth1     c869f6e8-0e81-433a-ad20-3caee07f54c2  ethernet  eth1
eth0                f29c6dae-a938-4814-b082-708b99c6a6ce  ethernet  --
Wired connection 1  89ad609e-4b4c-3622-8f35-8b7485b4b4bf  ethernet  --
[root@centos7 network-scripts]#

[root@centos7 network-scripts]#ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast master team0 state UP group default qlen 1000
    link/ether 00:0c:29:5f:6d:a3 brd ff:ff:ff:ff:ff:ff
3: eth1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast master team0 state UP group default qlen 1000
    link/ether 00:0c:29:5f:6d:a3 brd ff:ff:ff:ff:ff:ff
4: team0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default qlen 1000
    link/ether 00:0c:29:5f:6d:a3 brd ff:ff:ff:ff:ff:ff
    inet 10.0.0.102/24 brd 10.0.0.255 scope global noprefixroute team0
       valid_lft forever preferred_lft forever
    inet6 fe80::fa83:5293:a93a:3f66/64 scope link noprefixroute
       valid_lft forever preferred_lft forever
[root@centos7 network-scripts]#

#查看team接口状态
[root@centos7 network-scripts]#teamdctl team0 state
setup:
  runner: loadbalance
ports:
  eth0
    link watches:
      link summary: up
      instance[link_watch_0]:
        name: ethtool
        link: up
        down count: 0
  eth1
    link watches:
      link summary: up
      instance[link_watch_0]:
        name: ethtool
        link: up
        down count: 0
[root@centos7 network-scripts]#
```

`myteam0` 和 `team0` 在这个场景中分别表示连接名称（connection name）和接口名称（interface name）。

1. **连接名称（connection name）**：`myteam0` 是连接名称，它用于标识和管理 NetworkManager 中的特定网络连接配置。在本例中，`myteam0` 是用于表示 Team 接口配置的名称。当您使用 `nmcli` 或其他网络管理工具时，可以通过连接名称来引用、修改或删除特定的网络配置。
2. **接口名称（interface name）**：`team0` 是接口名称，它用于在操作系统层面表示实际的网络接口。接口名称通常在网络配置、监控和诊断过程中使用。例如，在执行 `ip` 命令、`ifconfig` 或 `ethtool` 时，需要使用接口名称来指定要操作的网络设备。

总之，连接名称（如 `myteam0`）主要用于在 NetworkManager 中引用和管理网络连接配置，而接口名称（如 `team0`）主要用于在操作系统层面表示和操作网络接口。这两者之间的区别在于它们在网络管理过程中的使用场景和目的。

### 3.4 name字段模式

在配置`team`接口时，`name`字段里的模式名称需要使用特定的字符串表示，而不是空格分隔的形式。因此，不能将`loadbalance`写成`load balance`。请务必遵循正确的配置语法。

除了`loadbalance`模式外，`team`还支持以下几种模式：

1. **roundrobin**：此模式下，数据包会依次在各个网络接口间轮询发送，从而实现负载均衡。
2. **activebackup**：在这种模式下，只有一个网络接口处于激活状态，其他接口处于备份状态。当激活接口出现故障时，备份接口会自动接管数据传输。这种模式主要用于实现高可用性。
3. **broadcast**：在此模式下，所有的数据包都会通过所有的网络接口发送，确保所有数据包都能到达目标。这种模式主要用于实现数据包的可靠传输。
4. **802.3ad (LACP)**：这种模式基于IEEE 802.3ad标准，需要交换机支持LACP（Link Aggregation Control Protocol）。它提供了负载均衡和故障切换功能。

要配置不同的`team`模式，请在`config`参数中的`runner`部分使用相应的模式名称。例如，要创建一个`roundrobin`模式的`team`接口，可以使用以下命令：

```css
sudo nmcli con add type team con-name team0 ifname team0 config '{"runner": {"name": "roundrobin"}}'
或者可以写成配置文件的形式
```

